{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(498, 2, 65, 2)\n",
      "(498, 2)\n",
      "(125, 2, 65, 2)\n",
      "(125, 2)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "import torch\n",
    "from fivesafe.object_detection import Detection_w_mask, draw_detection\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from utils.utils import PadHull, ScaleToImage, FlattenCoordinates\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from dataset import VehiclePSIDataset\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "dataset = VehiclePSIDataset(base_url='/Users/tobias/ziegleto/data/5Safe/carla/etron')\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_set, val_set = random_split(dataset, [train_size, test_size])\n",
    "train_dataloader = DataLoader(train_set, batch_size=train_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_set, batch_size=test_size, shuffle=True)\n",
    "    \n",
    "X_train, y_train = next(iter(train_dataloader))\n",
    "X_val, y_val = next(iter(val_dataloader))\n",
    "X_train = X_train.numpy()\n",
    "y_train = y_train.numpy()\n",
    "X_val = X_val.numpy()\n",
    "y_val = y_val.numpy()\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter()\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ddad97f08604d80b47bf9b634b20309",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(996, 130)\n",
      "(498, 2)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 31\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# commented out models don't work\u001b[39;00m\n\u001b[1;32m     20\u001b[0m classifiers \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     21\u001b[0m     (Ridge(random_state\u001b[38;5;241m=\u001b[39mrandom_state), scaled_pipeline),\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# RegressorChain(SVR()),\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m#(HardCodedEstimator(\"homography_matrix.json\", 1), None),\u001b[39;00m\n\u001b[1;32m     30\u001b[0m ]\n\u001b[0;32m---> 31\u001b[0m evaluation \u001b[38;5;241m=\u001b[39m fit_and_score(classifiers, X_train, y_train, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./evaluation_baseline.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     33\u001b[0m     w \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mDictWriter(f, evaluation[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys())\n",
      "Cell \u001b[0;32mIn[5], line 24\u001b[0m, in \u001b[0;36mfit_and_score\u001b[0;34m(classifiers, X, y, random_state)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_transformed\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(y\u001b[38;5;241m.\u001b[39mshape) \n\u001b[0;32m---> 24\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X_transformed, y, train_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m     26\u001b[0m classifier\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     28\u001b[0m y_pred_train \u001b[38;5;241m=\u001b[39m classifier\u001b[38;5;241m.\u001b[39mpredict(X_train)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor, RegressorChain\n",
    "import joblib\n",
    "#from utils.utils import fit_and_score, HardCodedEstimator\n",
    "\n",
    "scaled_pipeline = make_pipeline(#PadHull(False, n_points_per_hull),\n",
    "                               ScaleToImage(image_width, image_height),\n",
    "                               FlattenCoordinates(n_points_per_hull),\n",
    "                               StandardScaler()) # ridge needs standard scaler\n",
    "\n",
    "non_scaled_pipeline = make_pipeline(#PadHull(False, n_points_per_hull),\n",
    "                            ScaleToImage(image_width, image_height),\n",
    "                            FlattenCoordinates(n_points_per_hull),\n",
    "                            StandardScaler())\n",
    "\n",
    "# commented out models don't work\n",
    "classifiers = [\n",
    "    (Ridge(random_state=random_state), scaled_pipeline),\n",
    "    # RegressorChain(SVR()),\n",
    "    # MultiOutputRegressor(SVR()),\n",
    "    (RegressorChain(GradientBoostingRegressor(n_estimators=60, random_state=random_state)), non_scaled_pipeline),\n",
    "    (MultiOutputRegressor(GradientBoostingRegressor(n_estimators=60, random_state=random_state)), non_scaled_pipeline),\n",
    "    #RegressorChain(LinearSVR()),\n",
    "    # MultiOutputRegressor(LinearSVR()),\n",
    "    (DecisionTreeRegressor(max_depth=18, random_state=random_state), non_scaled_pipeline),\n",
    "    #(HardCodedEstimator(\"homography_matrix.json\", 1), None),\n",
    "]\n",
    "evaluation = fit_and_score(classifiers, X_train, y_train, random_state=random_state)\n",
    "with open(\"./evaluation_baseline.csv\", \"w\") as f:\n",
    "    w = csv.DictWriter(f, evaluation[0].keys())\n",
    "    w.writeheader()\n",
    "    w.writerows(evaluation)\n",
    "pp.pprint(evaluation)\n",
    "#_=joblib.dump(evaluation, \"classifiers.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BaseEstimator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mFlattenCoordinates\u001b[39;00m(BaseEstimator, TransformerMixin):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, n_coordinates: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BaseEstimator' is not defined"
     ]
    }
   ],
   "source": [
    "class FlattenCoordinates(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_coordinates: int) -> None:\n",
    "        super().__init__()\n",
    "        self.n_coordinates = n_coordinates\n",
    "        \n",
    "\n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # flatten all coordinates so they can fit into the models\n",
    "        return X.reshape(-1, self.n_coordinates*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(498, 2, 65, 2)\n",
      "(996, 130)\n"
     ]
    }
   ],
   "source": [
    "#pipeline = make_pipeline(#PadHull(False, n_points_per_hull),\n",
    "                          #  ScaleToImage(image_width, image_height),\n",
    "                           ## FlattenCoordinates(n_points_per_hull),\n",
    "                          #  StandardScaler())\n",
    "\n",
    "#X_train_transformed = pipeline.fit_transform(X_train.copy())\n",
    "#X_val_transformed = pipeline.fit_transform(X_val.copy())\n",
    "print(X_train.shape)\n",
    "sti = ScaleToImage(image_width, image_height)\n",
    "X_train_transformed = sti.transform(X_train)\n",
    "\n",
    "flat = FlattenCoordinates(65)\n",
    "X_train_transformed = flat.transform(X_train)\n",
    "print(X_train_transformed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(996, 130) (498, 2)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [996, 498]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m RegressorChain(GradientBoostingRegressor(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m60\u001b[39m, random_state\u001b[38;5;241m=\u001b[39mrandom_state))\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_train_transformed\u001b[38;5;241m.\u001b[39mshape, y_train\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m----> 3\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train_transformed, y_train)\n\u001b[1;32m      5\u001b[0m y_pred_train \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_train_transformed)\n\u001b[1;32m      6\u001b[0m train_mse \u001b[38;5;241m=\u001b[39m mean_squared_error(y_train, y_pred_train)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/multioutput.py:1149\u001b[0m, in \u001b[0;36mRegressorChain.fit\u001b[0;34m(self, X, Y, **fit_params)\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(\n\u001b[1;32m   1124\u001b[0m     \u001b[38;5;66;03m# RegressorChain.base_estimator is not validated yet\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m     prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1126\u001b[0m )\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model to data matrix X and targets Y.\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m \n\u001b[1;32m   1130\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;124;03m        Returns a fitted instance.\u001b[39;00m\n\u001b[1;32m   1148\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1149\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X, Y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m   1150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/multioutput.py:676\u001b[0m, in \u001b[0;36m_BaseChain.fit\u001b[0;34m(self, X, Y, **fit_params)\u001b[0m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;129m@abstractmethod\u001b[39m\n\u001b[1;32m    655\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):\n\u001b[1;32m    656\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model to data matrix X and targets Y.\u001b[39;00m\n\u001b[1;32m    657\u001b[0m \n\u001b[1;32m    658\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[38;5;124;03m        Returns a fitted instance.\u001b[39;00m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 676\u001b[0m     X, Y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, Y, multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    678\u001b[0m     random_state \u001b[38;5;241m=\u001b[39m check_random_state(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state)\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morder_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morder\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/base.py:622\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    620\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 622\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[1;32m    623\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/utils/validation.py:1164\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1146\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m   1147\u001b[0m     X,\n\u001b[1;32m   1148\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1159\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1160\u001b[0m )\n\u001b[1;32m   1162\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m-> 1164\u001b[0m check_consistent_length(X, y)\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/sklearn/utils/validation.py:407\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    405\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 407\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    408\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    409\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    410\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [996, 498]"
     ]
    }
   ],
   "source": [
    "model = RegressorChain(GradientBoostingRegressor(n_estimators=60, random_state=random_state))\n",
    "print(X_train_transformed.shape, y_train.shape)\n",
    "model.fit(X_train_transformed, y_train)\n",
    "\n",
    "y_pred_train = model.predict(X_train_transformed)\n",
    "train_mse = mean_squared_error(y_train, y_pred_train)\n",
    "\n",
    "y_pred_val = model.predict(X_val_transformed)\n",
    "test_mse = mean_squared_error(y_val, y_pred_val)\n",
    "\n",
    "print(train_mse, test_mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
